{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install yfinance  # yFinance version 0.2.4 is required. If there are problems, reinstall yfinance. 'pip unistall yfinance'\n",
    "# %pip install scipy\n",
    "# %pip install matplotlib\n",
    "# %pip install pyfolio\n",
    "# %pip uninstall pyfolio\n",
    "# %pip install git+https://github.com/quantopian/pyfolio\n",
    "# %pip install panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore printing all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import pyfolio as pf\n",
    "import datetime as dt\n",
    "import pandas_datareader.data as web\n",
    "import os\n",
    "# import warnings\n",
    "\n",
    "# print all outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_list = ['VNQ', 'EEM', 'DBC', 'SPY', 'TLT', 'SHY']\n",
    "rebalance_unit = 'Month'\n",
    "rebalance_freq = 1\n",
    "rebalance_shift = 0\n",
    "lb_period = 4\n",
    "skipped_period = 0\n",
    "no_played_ETFs = 3\n",
    "sub_rank_weights = {'relMom' : 0.5, 'volatility' : 0.25, 'correlation' : 0.25}\n",
    "abs_threshold = 0\n",
    "start_date = '2006-01-01'\n",
    "end_date = '2022-06-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  9 of 9 completed\n",
      "Couldn't download EMB ticker data. You might need to reinstall yfinance python library. (ver 0.2.4 is required)\n"
     ]
    }
   ],
   "source": [
    "tickers_list = ['SHY', 'IEF', 'TLT', 'TIP', 'LQD', 'HYG', 'BNDX', 'EMB', 'BIL']\n",
    "# tickers_list = ['BNDX']\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2023-01-05'\n",
    "#adj_close_price = yf.download(tickers_list)['Adj Close']\n",
    "adj_close_price = yf.download(tickers_list,start = pd.to_datetime(start_date) + pd.DateOffset(years= -2),end = pd.to_datetime(end_date) + pd.DateOffset(days= 1) )['Adj Close']\n",
    "adj_close_price.to_csv('D:\\Temp\\pricestonovellbond.csv')\n",
    "\n",
    "if len(adj_close_price['EMB']) > 0:\n",
    "    print(\"Couldn't download EMB ticker data. You might need to reinstall yfinance python library. (ver 0.2.4 is required)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_list2 = ['SPY', 'QQQ', 'IWM', 'VGK', 'EWJ', 'EEM', 'VNQ', 'DBC', 'GLD', 'HYG', 'LQD', 'TLT','IEF']\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2023-12-31'\n",
    "adj_close_price = yf.download(tickers_list2,start = pd.to_datetime(start_date) + pd.DateOffset(years= -2),end = pd.to_datetime(end_date) + pd.DateOffset(days= 1) )['Adj Close']\n",
    "adj_close_price.to_csv('D:\\Temp\\kellerprotmom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adj_close_price.copy()\n",
    "df['Year'], df['Month'], df['Week'] = df.index.year, df.index.month, df.index.week\n",
    "df['Monthly_Rb'] = df.Month != df.Month.shift(-1)\n",
    "df['Weekly_Rb'] = df.Week != df.Week.shift(-1)\n",
    "df['Daily_Rb'] = True\n",
    "df['RebalanceUnit'] = df.Monthly_Rb if rebalance_unit == 'Month' else df.Weekly_Rb if rebalance_unit == 'Week' else df.Daily_Rb\n",
    "df.RebalanceUnit = df.RebalanceUnit.shift(rebalance_shift).fillna(False) \n",
    "df.RebalanceUnit[0] = True\n",
    "df['NoPeriod'] = df.RebalanceUnit.shift(1).cumsum()\n",
    "df.NoPeriod[0] = 0\n",
    "df['NoData'] = np.arange(len(df)) + 1\n",
    "df['Rebalance'] = np.where((df.RebalanceUnit == True) & (df.NoPeriod.mod(rebalance_freq) == 0), True, False)\n",
    "# offset_start_helper = df.groupby('NoPeriod')['NoData'].max()\n",
    "# offset_start = offset_start_helper.shift(lb_period + skipped_period)\n",
    "# df.merge(offset_start, on = 'NoPeriod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyret = adj_close_price/adj_close_price.shift(1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_days_base = {'Month' : 21, 'Week' : 5, 'Day' : 1}\n",
    "lb_days = lb_days_base[rebalance_unit] * lb_period\n",
    "lb_days_with_skipped = lb_days_base[rebalance_unit] * (lb_period + skipped_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_mom_rets = adj_close_price.shift(lb_days_base[rebalance_unit] * skipped_period) / adj_close_price.shift(lb_days_with_skipped) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_rets_helper = dailyret.rolling(lb_days).std()\n",
    "sd_rets = sd_rets_helper.shift(lb_days_base[rebalance_unit] * skipped_period)\n",
    "corr_rets_helper = dailyret.rolling(lb_days).corr()\n",
    "corr_rets_helper2 = corr_rets_helper.groupby(corr_rets_helper.index.get_level_values('Date')).mean()\n",
    "corr_rets = corr_rets_helper2.shift(lb_days_base[rebalance_unit] * skipped_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_mom_rets_rank = rel_mom_rets.rank(axis = 1, ascending = False)\n",
    "sd_rets_rank = sd_rets.rank(axis = 1, ascending = True)\n",
    "corr_rets_rank = corr_rets.rank(axis = 1, ascending = True)\n",
    "# total_rank_helper = sub_rank_weights['relMom'] * rel_mom_rets_rank + sub_rank_weights['volatility'] * sd_rets_rank + sub_rank_weights['correlation'] * corr_rets_rank - rel_mom_rets/100\n",
    "total_rank_helper = sub_rank_weights['relMom'] * rel_mom_rets_rank + sub_rank_weights['volatility'] * sd_rets_rank + sub_rank_weights['correlation'] * corr_rets_rank\n",
    "total_rank = total_rank_helper.rank(axis = 1, ascending = True)\n",
    "no_selected_etfs = ((total_rank < no_played_ETFs + 1) & (rel_mom_rets > abs_threshold)).sum(1)\n",
    "no_really_played_etfs = no_selected_etfs.where(no_selected_etfs > no_played_ETFs, no_played_ETFs)\n",
    "etf_weights = (total_rank.divide(total_rank, axis = 0).divide(no_really_played_etfs, axis = 0)).where((total_rank < no_played_ETFs + 1) & (rel_mom_rets > abs_threshold), 0)\n",
    "cash_weight = 1 - etf_weights.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positions_pv(acp_p, rebalance_p, weights_p, cash_weight_p, start_date_p):\n",
    "    adjclose = acp_p.fillna(1).to_numpy()\n",
    "    rebalanceday = rebalance_p.to_numpy()\n",
    "    weights = weights_p.fillna(0).to_numpy()\n",
    "    cash_weight = cash_weight_p.to_numpy()\n",
    "    no_rows, no_cols = acp_p.shape\n",
    "\n",
    "    positions = np.zeros((no_rows, no_cols))\n",
    "    pv = np.ones((no_rows,1))\n",
    "    cash = np.ones((no_rows,1))\n",
    "    start_ind = np.argmax(acp_p.index >= start_date_p)\n",
    "    for i in range(start_ind, no_rows):\n",
    "        pv[i] = 0\n",
    "        for j in range(no_cols):\n",
    "            if rebalanceday[i-1] == True:\n",
    "                positions[i,j] = pv[i-1] * weights[i-1,j] / adjclose[i-1,j]                \n",
    "            else:\n",
    "                positions[i,j] = positions[i-1,j]\n",
    "            pv[i] += positions[i,j] * adjclose[i,j]\n",
    "        if rebalanceday[i-1] == True:\n",
    "            cash[i] = pv[i-1] * cash_weight[i-1]\n",
    "        else:\n",
    "            cash[i] = cash[i-1]\n",
    "        pv[i] += cash[i] \n",
    "    \n",
    "    positions_df = pd.DataFrame(positions, index = acp_p.index, columns = acp_p.columns)\n",
    "    positions_df_sel = positions_df.iloc[start_ind-1:no_rows,:]\n",
    "    pv_df =  pd.DataFrame(pv, index = acp_p.index)\n",
    "    pv_df_sel = pv_df.iloc[start_ind-1:no_rows,0]\n",
    "    cash_df =  pd.DataFrame(cash, index = acp_p.index)\n",
    "    cash_df_sel = cash_df.iloc[start_ind-1:no_rows,0]\n",
    "    return positions_df_sel, cash_df_sel, pv_df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positions_pv_ew(acp_p, rebalance_p, start_date_p):\n",
    "    adjclose = acp_p.fillna(0).to_numpy()\n",
    "    rebalanceday = rebalance_p.to_numpy()\n",
    "    no_rows, no_cols = acp_p.shape\n",
    "    no_ava_etfs = (acp_p > 0).sum(1)\n",
    "\n",
    "    positions = np.zeros((no_rows, no_cols))\n",
    "    pv = np.ones((no_rows,1))\n",
    "    cash = np.ones((no_rows,1))\n",
    "    start_ind = np.argmax(acp_p.index >= start_date_p)\n",
    "\n",
    "    pv[start_ind] = 0\n",
    "    for j in range(no_cols):\n",
    "        positions[start_ind, j] = pv[start_ind - 1] * (1 / no_ava_etfs[start_ind - 1]) / adjclose[start_ind - 1, j] if adjclose[start_ind - 1, j] > 0 else 0\n",
    "        pv[start_ind] += positions[start_ind, j] * adjclose[start_ind, j]\n",
    "    \n",
    "    for i in range(start_ind + 1, no_rows):\n",
    "        pv[i] = 0\n",
    "        for j in range(no_cols):\n",
    "            if rebalanceday[i-1] == True:\n",
    "                positions[i,j] = pv[i-1] * (1 / no_ava_etfs[i-1]) / adjclose[i-1,j] if adjclose[i-1, j] > 0 else 0                \n",
    "            else:\n",
    "                positions[i,j] = positions[i-1,j]\n",
    "            pv[i] += positions[i,j] * adjclose[i,j]\n",
    "        if rebalanceday[i-1] == True:\n",
    "            cash[i] = 0\n",
    "        else:\n",
    "            cash[i] = 0\n",
    "        pv[i] += cash[i] \n",
    "    \n",
    "    positions_df = pd.DataFrame(positions, index = acp_p.index, columns = acp_p.columns)\n",
    "    positions_df_sel = positions_df.iloc[start_ind-1:no_rows,:]\n",
    "    pv_df =  pd.DataFrame(pv, index = acp_p.index)\n",
    "    pv_df_sel = pv_df.iloc[start_ind-1:no_rows,0]\n",
    "    cash_df =  pd.DataFrame(cash, index = acp_p.index)\n",
    "    cash_df_sel = cash_df.iloc[start_ind-1:no_rows,0]\n",
    "    return positions_df_sel, cash_df_sel, pv_df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, cash, pv = positions_pv(adj_close_price, df.Rebalance, etf_weights, cash_weight, start_date)\n",
    "pos_ew, cash_ew, pv_ew = positions_pv_ew(adj_close_price, df.Rebalance, start_date)\n",
    "strat_rets = pv / pv.shift(1) - 1\n",
    "strat_rets_ew = pv_ew / pv_ew.shift(1) - 1\n",
    "weights2 = etf_weights.copy()\n",
    "weights2['cash'] = cash_weight\n",
    "pf.create_full_tear_sheet(strat_rets, positions = weights2, benchmark_rets = strat_rets_ew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # np.savetxt('outWeights.csv', pos, delimiter=';')\n",
    "# with open('csv_data1.csv', 'w') as csv_file:\n",
    "#     etf_weights.to_csv(path_or_buf=csv_file, sep = ';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b615d01120494f282c426459c34041206581ea59e4730aabec3fd78664a65ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
